{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3fcdacd4-84c8-4c5b-861a-270f3deed0d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Analysis of LLM Output\n",
    "\n",
    "This notebook contains the analysis for the output of the LLM data extraction process contained in the CCI Literature Analysis with LLM notebook. It processes the output dataframe to standardize the responses, then compiles and analyzes the references across a few different axes. \n",
    "\n",
    "Author: Josh Fuchs\n",
    "\n",
    "Copyright 2025, The University of North Carolina at Chapel Hill. Permission is granted to use in accordance with the MIT license. The code is licensed under the open-source MIT license.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "59d3ab74-7f17-444f-80d5-cec8931734bf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from typing import Union\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "42a9b591-a5fa-42b5-951a-d13ffd19de96",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Load Output DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8ff898d-1602-4ed8-a702-4145c6083a01",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "result_df = pd.read_csv('YOUR_PATH_HERE',index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9116edac-fad9-4015-bdc4-73ae0fc06004",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## DataFrame Preprocessing for Analysis\n",
    "\n",
    "Because the responses from the LLM are not completely standardized, there are three pre-analysis steps we need to take with the dataframe before conducting the final analysis. \n",
    "\n",
    "1. Standardize formatting for the columns of interest.\n",
    "2. Process papers that have multiple paragraphs. \n",
    "3. Standardize the response references."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "30c6febc-2b17-4b40-b13b-9baf130197b0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 1. Column Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9caa42d5-03db-41ba-b378-b9dc333be0c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Columns to format\n",
    "columns_to_format = ['q0', 'q1', 'q2']\n",
    "\n",
    "# Apply formatting: lowercase and remove periods\n",
    "for col in columns_to_format:\n",
    "    result_df[col] = result_df[col].str.lower().str.replace('.', '', regex=False)\n",
    "\n",
    "# Columns Q3 and Q4 have the results of the data extraction, so\n",
    "# they require some extra formatting to ensure consistency\n",
    "\n",
    "# Remove 'et al.,' from q3 and q4 columns\n",
    "result_df['q3'] = result_df['q3'].str.replace('et al.,', '', regex=False)\n",
    "result_df['q4'] = result_df['q4'].str.replace('et al.,', '', regex=False)\n",
    "\n",
    "# Replace all double spaces with single space\n",
    "result_df['q3'] = result_df['q3'].str.replace('  ', ' ', regex=False)\n",
    "result_df['q4'] = result_df['q4'].str.replace('  ', ' ', regex=False)\n",
    "\n",
    "# Replace None with NONE\n",
    "result_df['q3'] = result_df['q3'].str.replace('None', 'NONE', regex=False)\n",
    "result_df['q4'] = result_df['q4'].str.replace('None', 'NONE', regex=False)\n",
    "\n",
    "# Format column data types\n",
    "result_df['pmc'] = result_df['pmc'].astype('int')\n",
    "result_df['tokens_used'] = result_df['tokens_used'].astype('float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bfb7d9dd-6c5d-4798-b240-4e945cd6c2b7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 2. Deal with papers that have mutliple paragraphs analyzed\n",
    "\n",
    "Some articles have multiple paragraphs that contain references we are interested in. So these PMC IDs appear multiple times in our dataframe. Here we will de-duplicate these duplicated PMC IDs. We will also combine the extracted references to a single column named 'ref' so we can operate on a single column going forward. \n",
    "\n",
    "We will take the following steps to do this: \n",
    "\n",
    "1. Separate the duplicated and non-duplicated PMCs. Add the number of paragraphs present for all. \n",
    "2. For the PMCs that are duplicated, apply the following logic to determine the set of references used. This is implemented in the handle_duplicates function:\n",
    "    1. If the extracted reference is the same for all paragraphs, that is the reference. Keep the first occurrence.\n",
    "    2. If different paragraphs have different numbers of references, but they overlap (i.e. Charlson 1987, Quan 2005 then Charlson 1987), select the paragraph that has the most references. \n",
    "    3. If paragraphs have all NONE except one row, then keep the one row that is not NONE.\n",
    "    4. If paragraphs have separate references (i.e. Charlson 1987 then Quan 2005), combine all references into a single set. \n",
    "3. Concatenate duplicated and non-duplicated dataframes back together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "03d3c914-3a4f-4e35-b1e7-b7544c5471e5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def determine_ref(row: pd.Series) -> Union[str,float]:\n",
    "    '''\n",
    "    Combines references, which were determined in either Q3 or Q4,\n",
    "    into a single column. Assumes NaN response when that question\n",
    "    was not used\n",
    "\n",
    "    PARAMETERS:\n",
    "        row: a row of the dataframe\n",
    "\n",
    "    RETURNS:\n",
    "        a string containing the references\n",
    "    '''\n",
    "    if pd.isna(row['q3']) and pd.isna(row['q4']):\n",
    "        return np.nan\n",
    "    elif pd.isna(row['q3']):\n",
    "        return row['q4']\n",
    "    elif pd.isna(row['q4']):\n",
    "        return row['q3']\n",
    "    else:\n",
    "        return 'warning'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "083c2752-6054-46f8-8442-ffd940d5b386",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Merge the extracted references to a single\n",
    "# column named 'ref' using the determine_ref function\n",
    "result_df['ref'] = result_df.apply(determine_ref, axis=1)\n",
    "\n",
    "# Identify duplicated rows based on the 'PMC' column\n",
    "duplicated_pmc = result_df[result_df.duplicated('pmc', keep=False)].copy()\n",
    "\n",
    "# Add in a column that counts how many times each PMC value is duplicated\n",
    "duplicated_pmc.loc[:, 'paragraphs'] = duplicated_pmc.groupby('pmc')['pmc'].transform('count')\n",
    "\n",
    "# Drop the duplicated PMC rows from the original dataframe\n",
    "# This creates a dataframe where each PMC only appears once\n",
    "# We'll merge these together again later\n",
    "result_single_pmc_df = result_df.drop(duplicated_pmc.index)\n",
    "\n",
    "# Add in a column to keep track of number of extracted paragraphs\n",
    "# for the single PMC dataframe, this will be 1 unless \n",
    "result_single_pmc_df['paragraphs'] = np.where(result_single_pmc_df['paragraph'].isna(), 0, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d615b420-f391-4e1f-a882-2bdb2d459046",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Functions to handle each group of duplicates\n",
    "\n",
    "def process_refs(refs: list) -> str:\n",
    "    \"\"\"\n",
    "    Processes a list of reference strings, splitting them into sets and determining if any set is a superset of the others.\n",
    "\n",
    "    PARAMETERS:\n",
    "    refs : list\n",
    "        A list of reference strings, where each string contains references separated by commas.\n",
    "\n",
    "    RETURNS:\n",
    "    str : A sorted, comma-separated string of references. If any set is a superset of all other sets, returns the sorted superset. Otherwise, returns a sorted combination of all references.\n",
    "    \"\"\"\n",
    "\n",
    "    # Split references into sets, only if they are strings\n",
    "    ref_sets = [set(ref.split(', ')) for ref in refs if isinstance(ref, str)]\n",
    "    \n",
    "    # Check if any set is a superset of others\n",
    "    for i in range(len(ref_sets)):\n",
    "        if all(ref_sets[i].issuperset(ref_sets[j]) for j in range(len(ref_sets)) if i != j):\n",
    "            return ', '.join(sorted(ref_sets[i]))\n",
    "    \n",
    "    # Combine all references into a single set\n",
    "    combined_refs = set().union(*ref_sets)\n",
    "    return ', '.join(sorted(combined_refs))\n",
    "\n",
    "def handle_duplicates(group: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Handles duplicate references within a group of paragraphs by \n",
    "    determining the appropriate row to keep based on the values of the 'ref' column.\n",
    "\n",
    "    PARAMETERS:\n",
    "    group : DataFrame\n",
    "        A pandas DataFrame representing a group of rows with a 'ref' column containing reference values.\n",
    "\n",
    "    RETURNS:\n",
    "    DataFrame: A DataFrame containing only the row to keep based on the following conditions:\n",
    "        - If all 'ref' values are the same, keeps the first row.\n",
    "        - If all 'ref' values are 'NA' except for one, keeps the row with the non-'NA' value.\n",
    "        - Otherwise, processes the references using the `process_refs` function and updates the first row with the summarized reference, keeping only that row.\n",
    "    \"\"\"\n",
    "\n",
    "    unique_ref_values = group['ref'].unique()\n",
    "    \n",
    "    if len(unique_ref_values) == 1:\n",
    "        # If the value of 'ref' is the same for all, keep only the first row of that pmc group\n",
    "        return group.iloc[[0]]\n",
    "    elif pd.isna(group['ref']).sum() == len(group) - 1:\n",
    "        # If the value of 'ref' is 'NA' for all except 1 row, keep only that row of the pmc group\n",
    "        return group[~pd.isna(group['ref'])].iloc[[0]]\n",
    "    else:\n",
    "        # else, process refs using the process_refs function\n",
    "        # basically, we'll combine all the references into a single set\n",
    "        refs = group['ref'].tolist()\n",
    "        summarized_ref = process_refs(refs)\n",
    "        \n",
    "        # Update the first row with the summarized ref and keep only that row\n",
    "        group.iloc[0, group.columns.get_loc('ref')] = summarized_ref\n",
    "        return group.iloc[[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af89c8e4-d652-4c7f-a040-424f90a7b989",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Apply the function to each group of duplicates and concatenate the results\n",
    "duplicated_pmc_reduced = duplicated_pmc.groupby('pmc').apply(handle_duplicates).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "52f506c8-de2b-4457-a2d2-ded9037dad83",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Combine the duplicated and non-duplicated dataframes together\n",
    "cleaned_result_df = pd.concat([result_single_pmc_df, duplicated_pmc_reduced], axis=0,ignore_index=True)\n",
    "\n",
    "# Replace NaN values in the ref column with 'NOREF'\n",
    "# None means there was a reference but it wasn't used\n",
    "# NaN means there was no reference\n",
    "cleaned_result_df['ref'] = cleaned_result_df['ref'].fillna('NOREF')\n",
    "cleaned_result_df['ref'] = cleaned_result_df['ref'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8bfbf702-4395-4e47-addf-28b23a2e1611",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 3. Standardize the responded references\n",
    "\n",
    "Remove any references that are not to the selected CCI versions and ensure that references are formatted the same, with a comma between each for automated extraction. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "398f06bd-26af-4fd4-95e4-523c21f647f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Replace 'and' with ',' in 'ref' column and save to 'ref_clean' column\n",
    "cleaned_result_df['ref_clean'] = cleaned_result_df['ref'].str.replace(r'\\s+and\\s+', ',', regex=True,case=False)\n",
    "\n",
    "# Remove any instances of et al. or et al \n",
    "# We do the replacement directly on the ref_clean column so that we do not overwrite\n",
    "# the previous work\n",
    "cleaned_result_df['ref_clean'] = cleaned_result_df['ref_clean'].str.replace('et al.', '',regex=True)\n",
    "cleaned_result_df['ref_clean'] = cleaned_result_df['ref_clean'].str.replace('et al', '',regex=True)\n",
    "cleaned_result_df['ref_clean'] = cleaned_result_df['ref_clean'].str.replace('et al,', '',regex=True)\n",
    "\n",
    "# Replace any ; with ,\n",
    "cleaned_result_df['ref_clean'] = cleaned_result_df['ref_clean'].str.replace(';', ',',regex=True)\n",
    "\n",
    "# Replace any double spaces '  ' with single space ' '\n",
    "cleaned_result_df['ref_clean'] = cleaned_result_df['ref_clean'].str.replace('  ', ' ',regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "49814100-55b1-49af-98c4-4e31e859b619",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def filter_references(ref_list: str,valid_references: str) -> str:\n",
    "    \"\"\"\n",
    "    Filters a list of references, ensuring each reference appears only once and is valid.\n",
    "    Removes 'NONE' and 'NOREF' if there are other valid references.\n",
    "    Adds 'OTHER' if there are references not in valid_references.\n",
    "\n",
    "    PARAMETERS:\n",
    "    ref_list : str\n",
    "        A comma-separated string of references.\n",
    "    valid_references : set\n",
    "        A set of valid references.\n",
    "\n",
    "    RETURNS:\n",
    "    str: A comma-separated string of filtered references. If no valid references are found, returns \"OTHER\".\n",
    "    \"\"\"\n",
    "    refs = ref_list.split(',')\n",
    "    # Use set to ensure each reference only appears once\n",
    "    filtered_refs = {ref.strip() for ref in refs if ref.strip() in valid_references}\n",
    "    \n",
    "    # Check for invalid references and add 'OTHER' if any are found\n",
    "    if any(ref.strip() not in valid_references for ref in refs):\n",
    "        filtered_refs.add('OTHER')\n",
    "    \n",
    "    # Remove 'NONE' and 'NOREF' if there are other valid references\n",
    "    if filtered_refs - {'NONE', 'NOREF'}:\n",
    "        filtered_refs.discard('NONE')\n",
    "        filtered_refs.discard('NOREF')\n",
    "    \n",
    "    return ', '.join(filtered_refs) if filtered_refs else \"OTHER\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "479f65fc-7ad2-4cb8-946e-ad39e2f8a523",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# List of valid references\n",
    "# Keep NOREF and NONE because they indicate something\n",
    "# If the reference is not in the list, we'll return OTHER\n",
    "valid_references = ['Charlson 1987', 'Deyo 1992', 'Quan 2005', 'Quan 2011', 'Klabunde 2000',\n",
    "                    'Sundararajan 2004', 'Schneeweiss 2003','Halfon 2002', 'Charlson 1994',\n",
    "                    'Romano 1993', 'NOREF','NONE']\n",
    "\n",
    "# Apply the function to the ref_clean column\n",
    "cleaned_result_df['ref_clean_filtered'] = cleaned_result_df['ref_clean'].apply(lambda x: filter_references(x,valid_references))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dc81b652-a088-4655-aea8-9b023c13a55b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Final Dataframe Analysis\n",
    "\n",
    "Here are the questions we are interested in answering:\n",
    "1. How many papers cite none of the major versions?\n",
    "2. How many papers reference a CCI version, but don't actually calculate it? \n",
    "3. How often is each CCI version cited as a single reference?\n",
    "4. How often is each CCI version used, either individually or in combination? \n",
    "6. How often is there more than one paper cited, but our model picks out fewer as the versions used? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a187df0b-ec85-480f-9a77-ef0c20ebfd3b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"The number of papers analyzed is {}\".format(cleaned_result_df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c04056ae-e543-40cb-8de7-1991e5dcb8f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"The number of papers with one paragraph extracted is {}\".format(cleaned_result_df[cleaned_result_df['paragraphs'] == 1].shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73795f06-cd75-4ce2-8c4a-aa0f9267c7ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"The number of papers with more than one paragraph extracted is {}\".format(cleaned_result_df[cleaned_result_df['paragraphs'] > 1].shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "224e0214-f233-4096-8039-e3674d827edf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"The number of papers with no paragraphs extracted is {}\".format(cleaned_result_df[cleaned_result_df['paragraphs'] < 1].shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "69f0a060-7041-4caa-b77f-d93cee1fd72b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 1. How many papers cite none of the CCI versions? \n",
    "\n",
    "To calculate this we want to select where included_references == NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "00ecd877-be99-47a5-a9fc-d867b5151e29",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "no_citations = cleaned_result_df[cleaned_result_df['included_references'].isna()].shape[0]\n",
    "print(\"The number of papers with no citations is {}\".format(no_citations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d1b64c44-a0f7-4376-a760-600ce2a8472e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 2. How many papers reference a Charlson version, but don't actually calculate it? \n",
    "\n",
    "This can be answered with either Q0 = no, Q1 = no, or ref_clean_filtered = None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "07be306b-db00-424a-b285-dd3efb75a8fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "no_calculation = cleaned_result_df[(cleaned_result_df['q0'] == \"no\") \n",
    "                                   | (cleaned_result_df['q1'] == \"no\")\n",
    "                                   | (cleaned_result_df['ref_clean_filtered'] == \"NONE\")]\n",
    "print(\"The number of papers with no calculation is {}\".format(no_calculation.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "42535143-1fdf-48b6-83ff-f0383aaeecd3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 3. How often is each CCI version cited as a single reference?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c3f01642-3145-42e1-b318-25970ad47a90",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "versions = ['Charlson 1987', 'Deyo 1992', 'Romano 1993','Charlson 1994',\n",
    "            'Klabunde 2000','Halfon 2002','Schneeweiss 2003','Sundararajan 2004', \n",
    "            'Quan 2005', 'Quan 2011']\n",
    "\n",
    "for x in versions:\n",
    "    version_count = cleaned_result_df[cleaned_result_df['ref_clean_filtered'] == x].shape[0]\n",
    "    print(\"The number of papers that only cite {} is {}\".format(x, version_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1789c680-2487-48ea-a255-f4656944fa97",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 4. How often is each CCI version used, either individually or in combination?\n",
    "\n",
    "Here we will count versions that are part of multiple reference groups, such as citing both Charlson 1987 and Quan 2005 in the same paper. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d9888919-62d9-43de-a26b-27cc5aa3e61c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def count_unique_references(df: pd.DataFrame, column_name: str) -> Counter[str]:    \n",
    "    \"\"\"\n",
    "    Count the frequency of unique references in a specified column of a DataFrame.\n",
    "\n",
    "    This function processes each entry in the given column, assuming entries contain\n",
    "    comma-separated references. It strips whitespace and common punctuation from each\n",
    "    reference, then counts the occurrences of each unique reference across all entries.\n",
    "\n",
    "    Parameters:\n",
    "        df (pandas.DataFrame): The DataFrame containing the data.\n",
    "        column_name (str): The name of the column to analyze.\n",
    "\n",
    "    Returns:\n",
    "        collections.Counter: A Counter object mapping each unique reference to its frequency.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize a Counter to store the counts of unique references\n",
    "    reference_counter = Counter()\n",
    "    \n",
    "    # Iterate over each entry in the specified column\n",
    "    for entry in df[column_name]:\n",
    "        # Convert the entry to a string and split by comma\n",
    "        references = [ref.strip().strip(\"',[]\") for ref in str(entry).split(',')]\n",
    "        # Update the counter with the references\n",
    "        reference_counter.update(references)\n",
    "    \n",
    "    return reference_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "40260cf5-259a-4bb5-88dc-c46f30a2fa1f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Count unique references\n",
    "unique_refs = count_unique_references(cleaned_result_df,'ref_clean_filtered')\n",
    "print(unique_refs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0c1bd3d0-fb93-4465-b7fc-e80f8f8411f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 5. How often is there more than one paper cited, but our model picks out fewer as the versions used?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "636e047e-76b9-49fc-8d78-876d179a72a9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Exclude NaNs from included_references and calculate num_included_references as 1 + number of commas\n",
    "cleaned_result_df['num_included_references'] = cleaned_result_df['included_references'].apply(lambda x: 1 + x.count(',') if isinstance(x, str) else 0)\n",
    "\n",
    "# Calculate num_ref_clean_filtered as 1 + number of commas in ref_clean_filtered\n",
    "# if the value is None or 'NOREF', set num_ref_clean_filtered to 0\n",
    "cleaned_result_df['num_ref_clean_filtered'] = cleaned_result_df['ref_clean_filtered'].apply(\n",
    "    lambda x: 0 if x in [None, 'NOREF'] else 1 + x.count(',')\n",
    "    )\n",
    "\n",
    "# Compare num_included_references and num_ref_clean_filtered\n",
    "comparison_count = (cleaned_result_df['num_included_references'] > cleaned_result_df['num_ref_clean_filtered']).sum()\n",
    "\n",
    "print(f\"There are {cleaned_result_df[cleaned_result_df['num_included_references'] > 1].shape[0]} papers that cite more than one version of CCI.\")\n",
    "print(f\"There are {cleaned_result_df[cleaned_result_df['num_ref_clean_filtered'] > 1].shape[0]} papers that use more than version of CCI.\")\n",
    "print(f\"The number of times num_included_references is larger than num_ref_clean_filtered is {comparison_count}. This is different than above because this includes times when there would be a single version used. \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "51f7c0e5-d2f5-42ff-a0c8-b8c33b44df38",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Analysis By Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "50d75b37-7ccb-43c0-a791-9262d35087a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Identify single citations to the different versions\n",
    "\n",
    "version_count = cleaned_result_df[cleaned_result_df['ref_clean_filtered'] == 'Charlson 1987']\n",
    "version_count.groupby(\"pub_year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9fc4a314-9ee7-43f0-816c-63c09c8146fd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Identify any reference to the versions, including single and multiples\n",
    "filtered_df = cleaned_result_df[cleaned_result_df['ref_clean_filtered'].str.contains('Charlson 1994', na=False)]\n",
    "\n",
    "# Group by the pub_year column and count the occurrences\n",
    "grouped_counts = filtered_df.groupby('pub_year').size()\n",
    "\n",
    "# Print the counts per pub_year\n",
    "print(grouped_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ad6ab328-3556-4c26-85b8-f66d5e1ebfa5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Plot Percentages over year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "98eaeb14-4432-457d-8dd6-a2f97c21a914",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Removed Halfon 2002 since it has zero single references\n",
    "versions_limited = ['Charlson 1987', 'Deyo 1992', 'Romano 1993',\n",
    "            'Charlson 1994', 'Klabunde 2000', 'Schneeweiss 2003', \n",
    "            'Sundararajan 2004', 'Quan 2005', 'Quan 2011'\n",
    "            ]\n",
    "\n",
    "# Select rows that exactly match any of the strings in the versions\n",
    "filtered_df = cleaned_result_df[cleaned_result_df['ref_clean_filtered'].isin(versions_limited)]\n",
    "\n",
    "# Group by the pub_year column and count the occurrences for each string\n",
    "grouped_counts = filtered_df.groupby(['pub_year', 'ref_clean_filtered']).size().unstack(fill_value=0)\n",
    "\n",
    "# Calculate the total counts per year\n",
    "total_counts_per_year = grouped_counts.sum(axis=1)#filtered_df.groupby('pub_year').size()\n",
    "\n",
    "# Calculate the percentage for each string per year\n",
    "percentages = grouped_counts.div(total_counts_per_year, axis=0) * 100\n",
    "\n",
    "# Reset index for seaborn plotting\n",
    "percentages = percentages.reset_index()\n",
    "\n",
    "# Melt the DataFrame for seaborn plotting\n",
    "percentages_melted = percentages.melt(id_vars='pub_year', value_vars=versions_limited, var_name='String', value_name='Percentage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1fd27a3b-77b6-4916-aaca-f3ec7a898ab1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Get unique strings\n",
    "unique_strings = percentages_melted['String'].unique()\n",
    "\n",
    "# Create a 3x3 grid of plots\n",
    "fig, axes = plt.subplots(3, 3, figsize=(12, 5), sharex=True)\n",
    "\n",
    "# Flatten the axes array for easy iteration\n",
    "axes = axes.flatten()\n",
    "\n",
    "color_dict = {'Charlson 1987' : 'red',\n",
    "              'Deyo 1992' : 'red',\n",
    "              'Romano 1993' : 'black',\n",
    "            'Charlson 1994' : 'green',\n",
    "            'Klabunde 2000' : 'black',\n",
    "            'Schneeweiss 2003' : 'black', \n",
    "            'Sundararajan 2004' : 'black',\n",
    "            'Quan 2005' : 'green',\n",
    "            'Quan 2011' : 'green'\n",
    "}\n",
    "\n",
    "# Iterate over unique strings and create a plot for each\n",
    "for i, string in enumerate(unique_strings):\n",
    "    sns.lineplot(\n",
    "        data=percentages_melted[percentages_melted['String'] == string],\n",
    "        x='pub_year',\n",
    "        y='Percentage',\n",
    "        ax=axes[i],\n",
    "        color=color_dict[string],\n",
    "        linewidth=2.5\n",
    "    )\n",
    "    axes[i].text(0.5,0.85,string,\n",
    "                 fontsize=14,\n",
    "                 horizontalalignment='center',\n",
    "                 transform=axes[i].transAxes,)\n",
    "    axes[i].set_xlabel('Publication Year', fontsize=14)\n",
    "    axes[i].tick_params(axis='both', which='major', labelsize=14)\n",
    "    axes[i].xaxis.set_minor_locator(MultipleLocator(1))\n",
    "    if string in ('Charlson 1987', 'Charlson 1994', 'Sundararajan 2004'):\n",
    "        axes[i].set_ylabel('Percentage', fontsize=14)\n",
    "    else:\n",
    "        axes[i].set_ylabel('')\n",
    "    if string == 'Charlson 1987':\n",
    "        axes[i].set_ylim(0,100)\n",
    "        axes[i].yaxis.set_minor_locator(MultipleLocator(25))\n",
    "    else:\n",
    "        axes[i].set_ylim(0,20)\n",
    "        axes[i].yaxis.set_minor_locator(MultipleLocator(5))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "2 Analysis of LLM Output",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
